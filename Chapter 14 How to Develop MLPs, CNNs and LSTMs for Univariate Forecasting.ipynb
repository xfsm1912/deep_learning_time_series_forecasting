{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Deep learning neural networks are capable of automatically learning and extracting features from raw data. \n",
    "2. simple deep learning neural network models are capable of making skillful forecasts as compared to naive models and tuned SARIMA models on univariate time series forecasting problems that have both trend and seasonal components with no pre-processing.\n",
    "\n",
    "After completing this tutorial, you will know:\n",
    "- How to develop a robust test harness using walk-forward validation for evaluating the performance of neural network models.\n",
    "- How to develop and evaluate simple Multilayer Perceptron and convolutional neural networks for time series forecasting.\n",
    "- How to develop and evaluate LSTMs, CNN-LSTMs, and ConvLSTM neural network models for time series forecasting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.1 Tutorial Overview\n",
    "This tutorial is divided into five parts; they are: \n",
    "1. Time Series Problem\n",
    "2. Model Evaluation Test Harness\n",
    "3. Multilayer Perceptron Model\n",
    "4. Convolutional Neural Network Model \n",
    "5. Recurrent Neural Network Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.2 Time Series Problem\n",
    "- We will use the monthly car sales dataset as this context as it includes the complexity of both trend and seasonal elements. The monthly car sales dataset summarizes the monthly car sales in Quebec, Canada between 1960 and 1968. \n",
    "- The dataset is monthly and has nine years, or 108 observations. In our testing, will use the last year, or 12 observations, as the test set. \n",
    "- The dataset has an obvious trend and seasonal component. The period of the seasonal component could be six months or 12 months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.3 Model Evaluation Test Harness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test harness is a modified version of the framework presented in Chapter 11 and may cover much of the same of the same ground. This section is divided into the following parts:\n",
    "1. Train-Test Split\n",
    "2. Series as Supervised Learning\n",
    "3. Walk-Forward Validation\n",
    "4. Repeat Evaluation\n",
    "5. Summarize Performance \n",
    "6. Worked Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.1 Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.2 Series as Supervised Learning\n",
    "A supervised learning framing of a series means that the data needs to be split into multiple examples that the model learn from and generalize across. Each sample must have both an input component and an output component. The input component will be some number of prior observations, such as three years or 36 time steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.3 Walk-Forward Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.4 Repeat Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.5 Summarize Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.6 Worked Example\n",
    "\n",
    "we will calculate the median of a subset of prior observations relative to the time to be forecasted. We do not need to fit a model so the model fit() function will be implemented to simply return None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      " > 1841.156\n",
      "persistence: 1841.156 RMSE (+/- 0.000)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# persistence forecast for monthly car sales dataset\n",
    "from math import sqrt\n",
    "from numpy import median\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test], data[-n_test:]\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "\treturn sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# difference dataset\n",
    "def difference(data, interval):\n",
    "\treturn [data[i] - data[i - interval] for i in range(interval, len(data))]\n",
    "\n",
    "# fit a model\n",
    "def model_fit(train, config):\n",
    "\treturn None\n",
    "\n",
    "# forecast with a pre-fit model\n",
    "def model_predict(model, history, config):\n",
    "\tvalues = list()\n",
    "\tfor offset in config:\n",
    "\t\tvalues.append(history[-offset])\n",
    "\treturn median(values)\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# fit model\n",
    "\tmodel = model_fit(train, cfg)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# fit model and make forecast for history\n",
    "\t\tyhat = model_predict(model, history, cfg)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t# estimate prediction error\n",
    "\terror = measure_rmse(test, predictions)\n",
    "\tprint(' > %.3f' % error)\n",
    "\treturn error\n",
    "\n",
    "# repeat evaluation of a config\n",
    "def repeat_evaluate(data, config, n_test, n_repeats=30):\n",
    "\t# fit and evaluate the model n times\n",
    "\tscores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)]\n",
    "\treturn scores\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_scores(name, scores):\n",
    "\t# print a summary\n",
    "\tscores_m, score_std = mean(scores), std(scores)\n",
    "\tprint('%s: %.3f RMSE (+/- %.3f)' % (name, scores_m, score_std))\n",
    "\t# box and whisker plot\n",
    "\tpyplot.boxplot(scores)\n",
    "\tpyplot.show()\n",
    "\n",
    "series = read_csv('monthly-car-sales.csv', header=0, index_col=0)\n",
    "data = series.values\n",
    "# data split\n",
    "n_test = 12\n",
    "# define config\n",
    "config = [12, 24, 36]\n",
    "# grid search\n",
    "scores = repeat_evaluate(data, config, n_test)\n",
    "# summarize scores\n",
    "summarize_scores('persistence', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the RMSE of the model is 1841 sales, providing a lower-bound of performance by which we can evaluate whether a model is skillful or not on the problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.4 Multilayer Perceptron Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The first network that we will evaluate is a Multilayer Perceptron, or MLP for short. This is a simple feedforward neural network model that should be evaluated before more elaborate models are considered. \n",
    "- MLPs can be used for time series forecasting by taking multiple observations at prior time steps, called lag observations, and using them as input features and predicting one or more time steps from those observations. This is exactly the framing of the problem provided by the series to supervised() function in the previous section. \n",
    "\n",
    "X,  &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;y <br>\n",
    "month1, month2, month3, month4 <br>\n",
    "month2, month3, month4, month5 <br>\n",
    "month3, month4, month5, month6 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model fit() function for fitting an MLP model on the training dataset is listed below. The function expects the config to be a list with the following configuration hyperparameters:\n",
    "- n input: The number of lag observations to use as input to the model.\n",
    "- n nodes: The number of nodes to use in the hidden layer.\n",
    "- n epochs: The number of times to expose the model to the whole training dataset.\n",
    "- n batch: The number of samples within an epoch after which the weights are updated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when the training data is framed as a supervised learning problem, there are only 72 samples that can be used to train the model. Using a batch size of 72 or more means that the model is being trained using batch gradient descent instead of mini-batch gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jianhua/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0620 17:28:39.704894 4516132288 deprecation_wrapper.py:118] From /Users/Jianhua/anaconda/lib/python3.6/site-packages/tensorflow/__init__.py:99: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "W0620 17:28:39.705780 4516132288 deprecation_wrapper.py:118] From /Users/Jianhua/anaconda/lib/python3.6/site-packages/tensorflow/__init__.py:99: The name tf.AttrValue is deprecated. Please use tf.compat.v1.AttrValue instead.\n",
      "\n",
      "W0620 17:28:39.707077 4516132288 deprecation_wrapper.py:118] From /Users/Jianhua/anaconda/lib/python3.6/site-packages/tensorflow/__init__.py:99: The name tf.COMPILER_VERSION is deprecated. Please use tf.version.COMPILER_VERSION instead.\n",
      "\n",
      "W0620 17:28:39.708266 4516132288 deprecation_wrapper.py:118] From /Users/Jianhua/anaconda/lib/python3.6/site-packages/tensorflow/__init__.py:99: The name tf.CXX11_ABI_FLAG is deprecated. Please use tf.sysconfig.CXX11_ABI_FLAG instead.\n",
      "\n",
      "W0620 17:28:39.712933 4516132288 deprecation_wrapper.py:118] From /Users/Jianhua/anaconda/lib/python3.6/site-packages/tensorflow/__init__.py:99: The name tf.ConditionalAccumulator is deprecated. Please use tf.compat.v1.ConditionalAccumulator instead.\n",
      "\n",
      "W0620 17:28:39.915750 4516132288 deprecation_wrapper.py:118] From /Users/Jianhua/anaconda/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1578.923\n",
      " > 1560.381\n",
      " > 1373.395\n",
      " > 1739.538\n",
      " > 1761.065\n",
      " > 1559.661\n",
      " > 1699.333\n",
      " > 1586.307\n",
      " > 1595.143\n",
      " > 1695.266\n",
      " > 1515.707\n",
      " > 1524.551\n",
      " > 1550.607\n",
      " > 1623.120\n",
      " > 1504.344\n",
      " > 1546.014\n",
      " > 1461.201\n",
      " > 1383.940\n",
      " > 1806.006\n",
      " > 1609.717\n",
      " > 1560.840\n",
      " > 1367.168\n",
      " > 1454.874\n",
      " > 1449.245\n",
      " > 1317.731\n",
      " > 2051.709\n",
      " > 1706.215\n",
      " > 1370.686\n",
      " > 1326.256\n",
      " > 1486.264\n",
      "mlp: 1558.840 RMSE (+/- 157.060)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate mlp for monthly car sales dataset\n",
    "from math import sqrt\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test], data[-n_test:]\n",
    "\n",
    "# transform list into supervised learning format\n",
    "def series_to_supervised(data, n_in, n_out=1):\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "\treturn sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# fit a model\n",
    "def model_fit(train, config):\n",
    "\t# unpack config\n",
    "\tn_input, n_nodes, n_epochs, n_batch = config\n",
    "\t# prepare data\n",
    "\tdata = series_to_supervised(train, n_input)\n",
    "\ttrain_x, train_y = data[:, :-1], data[:, -1]\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(n_nodes, activation='relu', input_dim=n_input))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\t# fit\n",
    "\tmodel.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n",
    "\treturn model\n",
    "\n",
    "# forecast with a pre-fit model\n",
    "def model_predict(model, history, config):\n",
    "\t# unpack config\n",
    "\tn_input, _, _, _ = config\n",
    "\t# prepare data\n",
    "\tx_input = array(history[-n_input:]).reshape(1, n_input)\n",
    "\t# forecast\n",
    "\tyhat = model.predict(x_input, verbose=0)\n",
    "\treturn yhat[0]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# fit model\n",
    "\tmodel = model_fit(train, cfg)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# fit model and make forecast for history\n",
    "\t\tyhat = model_predict(model, history, cfg)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t# estimate prediction error\n",
    "\terror = measure_rmse(test, predictions)\n",
    "\tprint(' > %.3f' % error)\n",
    "\treturn error\n",
    "\n",
    "# repeat evaluation of a config\n",
    "def repeat_evaluate(data, config, n_test, n_repeats=30):\n",
    "\t# fit and evaluate the model n times\n",
    "\tscores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)]\n",
    "\treturn scores\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_scores(name, scores):\n",
    "\t# print a summary\n",
    "\tscores_m, score_std = mean(scores), std(scores)\n",
    "\tprint('%s: %.3f RMSE (+/- %.3f)' % (name, scores_m, score_std))\n",
    "\t# box and whisker plot\n",
    "\tpyplot.boxplot(scores)\n",
    "\tpyplot.show()\n",
    "\n",
    "series = read_csv('monthly-car-sales.csv', header=0, index_col=0)\n",
    "data = series.values\n",
    "# data split\n",
    "n_test = 12\n",
    "# define config\n",
    "config = [24, 500, 100, 100]\n",
    "# grid search\n",
    "scores = repeat_evaluate(data, config, n_test)\n",
    "# summarize scores\n",
    "summarize_scores('mlp', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that although on average the performance of the model is impressive, the spread is large. The standard deviation is a little more than 134 sales, meaning a worse case model run that is 2 or 3 standard deviations in error from the mean error may be worse than the naive model. A challenge in using the MLP model is in harnessing the higher skill and minimizing the variance of the model across multiple runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.5 Convolutional Neural Network Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We will define a CNN with two convolutional layers for extracting features from the input sequences. Each will have a configurable number of filters and kernel size and will use the rectified linear activation function. The number of filters determines the number of parallel fields on which the weighted inputs are read and projected. The kernel size defines the number of time steps read within each snapshot as the network reads along the input sequence.\n",
    "\n",
    "2. The CNN model expects input data to be in the form of multiple samples, where each sample has multiple input time steps, the same as the MLP in the previous section. One difference is that the CNN can support multiple features or types of observations at each time step, which are interpreted as channels of an image. We only have a single feature at each time step, therefore the required three-dimensional shape of the input data will be [n samples, n input, 1].\n",
    "\n",
    "3. The model fit() function for fitting the CNN model on the training dataset is listed below. The model takes the following five configuration parameters as a list:\n",
    "   - n_input: The number of lag observations to use as input to the model.\n",
    "   - n_filters: The number of parallel filters.\n",
    "   - n_kernel: The number of time steps considered in each read of the input sequence.\n",
    "   - n_epochs: The number of times to expose the model to the whole training dataset.\n",
    "   - n_batch: The number of samples within an epoch after which the weights are updated.\n",
    "   \n",
    "4. Making a prediction with the fit CNN model is very much like making a prediction with the fit MLP model in the previous section. The one difference is in the requirement that we specify the number of features observed at each time step, which in this case is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0620 18:09:44.556500 4516132288 deprecation_wrapper.py:118] From /Users/Jianhua/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1612.899\n",
      " > 1508.631\n",
      " > 1511.113\n",
      " > 1580.887\n",
      " > 1544.531\n",
      " > 1455.062\n",
      " > 1488.155\n",
      " > 1588.717\n",
      " > 1473.459\n",
      " > 1511.153\n",
      " > 1609.956\n",
      " > 1541.240\n",
      " > 1510.402\n",
      " > 1565.353\n",
      " > 1486.451\n",
      " > 1600.393\n",
      " > 1656.380\n",
      " > 1518.757\n",
      " > 1422.331\n",
      " > 1658.227\n",
      " > 1440.192\n",
      " > 1513.167\n",
      " > 1485.856\n",
      " > 1447.541\n",
      " > 1604.083\n",
      " > 1487.400\n",
      " > 1495.686\n",
      " > 1520.420\n",
      " > 1545.942\n",
      " > 1491.291\n",
      "cnn: 1529.189 RMSE (+/- 60.935)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate cnn  for monthly car sales dataset\n",
    "from math import sqrt\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test], data[-n_test:]\n",
    "\n",
    "# transform list into supervised learning format\n",
    "def series_to_supervised(data, n_in, n_out=1):\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = []\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "\treturn sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# fit a model\n",
    "def model_fit(train, config):\n",
    "\t# unpack config\n",
    "\tn_input, n_filters, n_kernel, n_epochs, n_batch = config\n",
    "\t# prepare data\n",
    "\tdata = series_to_supervised(train, n_input)\n",
    "\ttrain_x, train_y = data[:, :-1], data[:, -1]\n",
    "\ttrain_x = train_x.reshape((train_x.shape[0], train_x.shape[1], 1))\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv1D(filters=n_filters, kernel_size=n_kernel, activation='relu', input_shape=(n_input, 1)))\n",
    "\tmodel.add(Conv1D(filters=n_filters, kernel_size=n_kernel, activation='relu'))\n",
    "\tmodel.add(MaxPooling1D(pool_size=2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\t# fit\n",
    "\tmodel.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n",
    "\treturn model\n",
    "\n",
    "# forecast with a pre-fit model\n",
    "def model_predict(model, history, config):\n",
    "\t# unpack config\n",
    "\tn_input, _, _, _, _ = config\n",
    "\t# prepare data\n",
    "\tx_input = array(history[-n_input:]).reshape((1, n_input, 1))\n",
    "\t# forecast\n",
    "\tyhat = model.predict(x_input, verbose=0)\n",
    "\treturn yhat[0]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "\tpredictions = []\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# fit model\n",
    "\tmodel = model_fit(train, cfg)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# fit model and make forecast for history\n",
    "\t\tyhat = model_predict(model, history, cfg)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t# estimate prediction error\n",
    "\terror = measure_rmse(test, predictions)\n",
    "\tprint(' > %.3f' % error)\n",
    "\treturn error\n",
    "\n",
    "# repeat evaluation of a config\n",
    "def repeat_evaluate(data, config, n_test, n_repeats=30):\n",
    "\t# fit and evaluate the model n times\n",
    "\tscores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)]\n",
    "\treturn scores\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_scores(name, scores):\n",
    "\t# print a summary\n",
    "\tscores_m, score_std = mean(scores), std(scores)\n",
    "\tprint('%s: %.3f RMSE (+/- %.3f)' % (name, scores_m, score_std))\n",
    "\t# box and whisker plot\n",
    "\tpyplot.boxplot(scores)\n",
    "\tpyplot.show()\n",
    "\n",
    "series = read_csv('monthly-car-sales.csv', header=0, index_col=0)\n",
    "data = series.values\n",
    "# data split\n",
    "n_test = 12\n",
    "# define config\n",
    "config = [36, 256, 3, 100, 100]\n",
    "# grid search\n",
    "scores = repeat_evaluate(data, config, n_test)\n",
    "# summarize scores\n",
    "summarize_scores('cnn', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A box and whisker plot of the scores is created to help understand the spread of error across the runs. We can see that the spread does seem to be biased towards larger error values, as we would expect, although the upper whisker of the plot (in this case, the largest error that are not outliers) is still limited at an RMSE of 1,650 sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.6 Recurrent Neural Network Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM achieves this by learning the weights for internal gates that control the recurrent connections within each node. Although developed for sequence data, LSTMs have not proven effective on time series forecasting problems where the output is a function of recent observations, e.g. an autoregressive type forecasting problem, such as the car sales dataset.\n",
    "\n",
    "In this section, we will explore three variations on the LSTM model for univariate time series forecasting; they are:\n",
    "- Vanilla LSTM: The LSTM network as-is.\n",
    "- CNN-LSTM: A CNN network that learns input features and an LSTM that interprets them.\n",
    "- ConvLSTM: A combination of CNNs and LSTMs where the LSTM units read input data using the convolutional process of a CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.6.1 LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The LSTM has an internal memory allowing it to accumulate internal state as it reads across the steps of a given input sequence. At the end of the sequence, each node in a layer of hidden LSTM units will output a single value. This vector of values summarizes what the LSTM learned or extracted from the input sequence. \n",
    "2. Like the CNN, the LSTM can support multiple variables or features at each time step.\n",
    "3. Unlike the MLP and CNN that do not read the sequence data one-step at a time, the LSTM does perform better if the data is stationary. This means that difference operations are performed to remove the trend and seasonal structure. In the case of the car sales dataset, we can make the data stationery by performing a seasonal adjustment, that is subtracting the value from one year ago from each observation.\n",
    "4. The model expects a list of five model hyperparameters; they are:\n",
    "   - n_input: The number of lag observations to use as input to the model.\n",
    "   - n_nodes: The number of LSTM units to use in the hidden layer. so it is the hidden state's dimention\n",
    "   - n_epochs: The number of times to expose the model to the whole training dataset.\n",
    "   - n_batch: The number of samples within an epoch after which the weights are updated. Ùè∞Ä n diff: The difference order or 0 if not used.\n",
    "   \n",
    "5. A single input must have the three-dimensional structure of samples, time steps, and features, which in this case we only have 1 sample and 1 feature: [1, n input, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0621 15:48:07.784037 4516132288 deprecation.py:323] From /Users/Jianhua/anaconda/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1251: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2155.219\n",
      " > 2164.798\n",
      " > 2263.603\n",
      " > 2007.743\n",
      " > 2097.716\n",
      " > 2198.252\n",
      " > 2230.124\n",
      " > 2139.607\n",
      " > 2139.256\n",
      " > 2086.815\n",
      " > 2202.545\n",
      " > 2150.428\n",
      " > 2107.046\n",
      " > 2148.965\n",
      " > 2093.644\n",
      " > 2390.682\n",
      " > 2236.974\n",
      " > 2133.859\n",
      " > 2155.832\n",
      " > 2102.451\n",
      " > 2075.621\n",
      " > 2079.749\n",
      " > 2113.700\n",
      " > 2169.144\n",
      " > 2167.746\n",
      " > 2107.339\n",
      " > 2140.099\n",
      " > 2061.618\n",
      " > 2187.312\n",
      " > 2101.745\n",
      "lstm: 2146.988 RMSE (+/- 70.843)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate lstm for monthly car sales dataset\n",
    "from math import sqrt\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test], data[-n_test:]\n",
    "\n",
    "# transform list into supervised learning format\n",
    "def series_to_supervised(data, n_in, n_out=1):\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "\treturn sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# difference dataset\n",
    "def difference(data, interval):\n",
    "\treturn [data[i] - data[i - interval] for i in range(interval, len(data))]\n",
    "\n",
    "# fit a model\n",
    "def model_fit(train, config):\n",
    "\t# unpack config\n",
    "\tn_input, n_nodes, n_epochs, n_batch, n_diff = config\n",
    "\t# prepare data\n",
    "\tif n_diff > 0:\n",
    "\t\ttrain = difference(train, n_diff)\n",
    "\tdata = series_to_supervised(train, n_input)\n",
    "\ttrain_x, train_y = data[:, :-1], data[:, -1]\n",
    "\ttrain_x = train_x.reshape((train_x.shape[0], train_x.shape[1], 1))\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(n_nodes, activation='relu', input_shape=(n_input, 1)))\n",
    "\tmodel.add(Dense(n_nodes, activation='relu'))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\t# fit\n",
    "\tmodel.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n",
    "\treturn model\n",
    "\n",
    "# forecast with a pre-fit model\n",
    "def model_predict(model, history, config):\n",
    "\t# unpack config\n",
    "\tn_input, _, _, _, n_diff = config\n",
    "\t# prepare data\n",
    "\tcorrection = 0.0\n",
    "\tif n_diff > 0:\n",
    "\t\tcorrection = history[-n_diff]\n",
    "\t\thistory = difference(history, n_diff)\n",
    "\tx_input = array(history[-n_input:]).reshape((1, n_input, 1))\n",
    "\t# forecast\n",
    "\tyhat = model.predict(x_input, verbose=0)\n",
    "\treturn correction + yhat[0]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# fit model\n",
    "\tmodel = model_fit(train, cfg)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# fit model and make forecast for history\n",
    "\t\tyhat = model_predict(model, history, cfg)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t# estimate prediction error\n",
    "\terror = measure_rmse(test, predictions)\n",
    "\tprint(' > %.3f' % error)\n",
    "\treturn error\n",
    "\n",
    "# repeat evaluation of a config\n",
    "def repeat_evaluate(data, config, n_test, n_repeats=30):\n",
    "\t# fit and evaluate the model n times\n",
    "\tscores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)]\n",
    "\treturn scores\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_scores(name, scores):\n",
    "\t# print a summary\n",
    "\tscores_m, score_std = mean(scores), std(scores)\n",
    "\tprint('%s: %.3f RMSE (+/- %.3f)' % (name, scores_m, score_std))\n",
    "\t# box and whisker plot\n",
    "\tpyplot.boxplot(scores)\n",
    "\tpyplot.show()\n",
    "\n",
    "series = read_csv('monthly-car-sales.csv', header=0, index_col=0)\n",
    "data = series.values\n",
    "# data split\n",
    "n_test = 12\n",
    "# define config\n",
    "config = [36, 50, 100, 100, 12]\n",
    "# grid search\n",
    "scores = repeat_evaluate(data, config, n_test)\n",
    "# summarize scores\n",
    "summarize_scores('lstm', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the run, we can see that the average RMSE is about 2,109, which is worse than the naive model. This suggests that the chosen model is not skillful, and it was the best that could be found given the same resources used to find model configurations in the previous sections. This provides further evidence (although weak evidence) that LSTMs, at least alone, are perhaps a bad fit for autoregressive-type sequence prediction problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.6.2 CNN LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We can combine this capability with the LSTM where a CNN model is applied to sub-sequences of input data, the results of which together form a time series of extracted features that can be interpreted by an LSTM model. This combination of a CNN model used to read multiple subsequences over time by an LSTM is called a CNN-LSTM model. \n",
    "2. The model requires that each input sequence, e.g. 36 months, is divided into multiple subsequences, each read by the CNN model, e.g. 3 subsequence of 12 time steps. Therefore, this splitting is parameterized with the n seq and n steps for the number of subsequences and number of steps per subsequence parameters.\n",
    "3. The number of lag observations per sample is simply (n_seq $\\times$ n_steps). This is a 4- dimensional input array now with the dimensions: [samples, subsequences, timesteps, features]. The same CNN model must be applied to each input subsequence. We can achieve this by wrapping the entire CNN model in a TimeDistributed layer wrapper.\n",
    "4. The output of one application of the CNN submodel will be a vector. The output of the submodel to each input subsequence will be a time series of interpretations that can be interpreted by an LSTM model. \n",
    "5. The model expects a list of seven hyperparameters; they are:\n",
    "   - n_seq: The number of subsequences within a sample.\n",
    "   - n_steps: The number of time steps within each subsequence.\n",
    "   - n_filters: The number of parallel filters.\n",
    "   - n_kernel: The number of time steps considered in each read of the input sequence.\n",
    "   - n_nodes: The number of LSTM units to use in the hidden layer.\n",
    "   - n_epochs: The number of times to expose the model to the whole training dataset.\n",
    "   - n_batch: The number of samples within an epoch after which the weights are updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1466.232\n",
      " > 1649.687\n",
      " > 1953.968\n",
      " > 1710.558\n",
      " > 1960.039\n",
      " > 1719.947\n",
      " > 1364.541\n",
      " > 1733.133\n",
      " > 1365.926\n",
      " > 1592.421\n",
      " > 1724.963\n",
      " > 1843.420\n",
      " > 1439.914\n",
      " > 1694.081\n",
      " > 3730.331\n",
      " > 1500.166\n",
      " > 1752.941\n",
      " > 1608.283\n",
      " > 1659.277\n",
      " > 1508.029\n",
      " > 1581.717\n",
      " > 1772.822\n",
      " > 1522.565\n",
      " > 1569.584\n",
      " > 1819.870\n",
      " > 2223.411\n",
      " > 1558.730\n",
      " > 1728.498\n",
      " > 1596.333\n",
      " > 2022.626\n",
      "cnn-lstm: 1745.800 RMSE (+/- 414.575)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate cnn-lstm for monthly car sales dataset\n",
    "from math import sqrt\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test], data[-n_test:]\n",
    "\n",
    "# transform list into supervised learning format\n",
    "def series_to_supervised(data, n_in, n_out=1):\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "\treturn sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# fit a model\n",
    "def model_fit(train, config):\n",
    "\t# unpack config\n",
    "\tn_seq, n_steps, n_filters, n_kernel, n_nodes, n_epochs, n_batch = config\n",
    "\tn_input = n_seq * n_steps\n",
    "\t# prepare data\n",
    "\tdata = series_to_supervised(train, n_input)\n",
    "\ttrain_x, train_y = data[:, :-1], data[:, -1]\n",
    "\ttrain_x = train_x.reshape((train_x.shape[0], n_seq, n_steps, 1))\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(TimeDistributed(Conv1D(filters=n_filters, kernel_size=n_kernel, activation='relu', input_shape=(None,n_steps,1))))\n",
    "\tmodel.add(TimeDistributed(Conv1D(filters=n_filters, kernel_size=n_kernel, activation='relu')))\n",
    "\tmodel.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "\tmodel.add(TimeDistributed(Flatten()))\n",
    "\tmodel.add(LSTM(n_nodes, activation='relu'))\n",
    "\tmodel.add(Dense(n_nodes, activation='relu'))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\t# fit\n",
    "\tmodel.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n",
    "\treturn model\n",
    "\n",
    "# forecast with a pre-fit model\n",
    "def model_predict(model, history, config):\n",
    "\t# unpack config\n",
    "\tn_seq, n_steps, _, _, _, _, _ = config\n",
    "\tn_input = n_seq * n_steps\n",
    "\t# prepare data\n",
    "\tx_input = array(history[-n_input:]).reshape((1, n_seq, n_steps, 1))\n",
    "\t# forecast\n",
    "\tyhat = model.predict(x_input, verbose=0)\n",
    "\treturn yhat[0]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# fit model\n",
    "\tmodel = model_fit(train, cfg)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# fit model and make forecast for history\n",
    "\t\tyhat = model_predict(model, history, cfg)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t# estimate prediction error\n",
    "\terror = measure_rmse(test, predictions)\n",
    "\tprint(' > %.3f' % error)\n",
    "\treturn error\n",
    "\n",
    "# repeat evaluation of a config\n",
    "def repeat_evaluate(data, config, n_test, n_repeats=30):\n",
    "\t# fit and evaluate the model n times\n",
    "\tscores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)]\n",
    "\treturn scores\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_scores(name, scores):\n",
    "\t# print a summary\n",
    "\tscores_m, score_std = mean(scores), std(scores)\n",
    "\tprint('%s: %.3f RMSE (+/- %.3f)' % (name, scores_m, score_std))\n",
    "\t# box and whisker plot\n",
    "\tpyplot.boxplot(scores)\n",
    "\tpyplot.show()\n",
    "\n",
    "series = read_csv('monthly-car-sales.csv', header=0, index_col=0)\n",
    "data = series.values\n",
    "# data split\n",
    "n_test = 12\n",
    "# define config\n",
    "config = [3, 12, 64, 3, 100, 200, 100]\n",
    "# grid search\n",
    "scores = repeat_evaluate(data, config, n_test)\n",
    "# summarize scores\n",
    "summarize_scores('cnn-lstm', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example prints the RMSE for each repeated evaluation of the model. The final averaged RMSE is reported at the end of about 1,626, which is lower than the naive model, but still higher than a SARIMA model. The standard deviation of this score is also very large, suggesting that the chosen configuration may not be as stable as the standalone CNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.6.3 ConvLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. It is possible to perform a convolutional operation as part of the read of the input sequence within each LSTM unit. Rather than reading a sequence one step at a time, the LSTM would read a block or subsequence of obvervations at a time using a convolutional process, like a CNN. this is performing the CNN operation at each time step as part of the LSTM.\n",
    "2. This type of model is called a Convolutional LSTM, or ConvLSTM for short. It is provided in Keras as a layer called ConvLSTM2D for 2D data. We can configure it for use with 1D sequence data by assuming that we have one row with multiple columns. \n",
    "3. The output of the layer is a sequence of filter maps that must first be flattened before it can be interpreted and followed by an output layer. The model expects a list of seven hyperparameters, the same as the CNN-LSTM; they are:\n",
    "   - n_seq: The number of subsequences within a sample.\n",
    "   - n_steps: The number of time steps within each subsequence.\n",
    "   - n_filters: The number of parallel filters.\n",
    "   - n_kernel: The number of time steps considered in each read of the input sequence.\n",
    "   - n_nodes: The number of LSTM units to use in the hidden layer.\n",
    "   - n_epochs: The number of times to expose the model to the whole training dataset.\n",
    "   - n_batch: The number of samples within an epoch after which the weights are updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1609.249\n",
      " > 1844.314\n",
      " > 1612.016\n",
      " > 1498.485\n",
      " > 1599.419\n",
      " > 1902.449\n",
      " > 1742.051\n",
      " > 2228.348\n",
      " > 1268.056\n",
      " > 2043.820\n",
      " > 2421.004\n",
      " > 1844.636\n",
      " > 1800.341\n",
      " > 1687.433\n",
      " > 1357.723\n",
      " > 1788.538\n",
      " > 2238.601\n",
      " > 2027.296\n",
      " > 2016.788\n",
      " > 1458.253\n",
      " > 2117.089\n",
      " > 1578.218\n",
      " > 1717.727\n",
      " > 1746.030\n",
      " > 1357.530\n",
      " > 2147.564\n",
      " > 1706.005\n",
      " > 1734.211\n",
      " > 2220.085\n",
      " > 1698.368\n",
      "convlstm: 1800.388 RMSE (+/- 284.277)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate convlstm for monthly car sales dataset\n",
    "from math import sqrt\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import ConvLSTM2D\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test], data[-n_test:]\n",
    "\n",
    "# transform list into supervised learning format\n",
    "def series_to_supervised(data, n_in, n_out=1):\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "\treturn sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# difference dataset\n",
    "def difference(data, interval):\n",
    "\treturn [data[i] - data[i - interval] for i in range(interval, len(data))]\n",
    "\n",
    "# fit a model\n",
    "def model_fit(train, config):\n",
    "\t# unpack config\n",
    "\tn_seq, n_steps, n_filters, n_kernel, n_nodes, n_epochs, n_batch = config\n",
    "\tn_input = n_seq * n_steps\n",
    "\t# prepare data\n",
    "\tdata = series_to_supervised(train, n_input)\n",
    "\ttrain_x, train_y = data[:, :-1], data[:, -1]\n",
    "\ttrain_x = train_x.reshape((train_x.shape[0], n_seq, 1, n_steps, 1))\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(ConvLSTM2D(filters=n_filters, kernel_size=(1,n_kernel), activation='relu', input_shape=(n_seq, 1, n_steps, 1)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(n_nodes, activation='relu'))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\t# fit\n",
    "\tmodel.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n",
    "\treturn model\n",
    "\n",
    "# forecast with a pre-fit model\n",
    "def model_predict(model, history, config):\n",
    "\t# unpack config\n",
    "\tn_seq, n_steps, _, _, _, _, _ = config\n",
    "\tn_input = n_seq * n_steps\n",
    "\t# prepare data\n",
    "\tx_input = array(history[-n_input:]).reshape((1, n_seq, 1, n_steps, 1))\n",
    "\t# forecast\n",
    "\tyhat = model.predict(x_input, verbose=0)\n",
    "\treturn yhat[0]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# fit model\n",
    "\tmodel = model_fit(train, cfg)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# fit model and make forecast for history\n",
    "\t\tyhat = model_predict(model, history, cfg)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t# estimate prediction error\n",
    "\terror = measure_rmse(test, predictions)\n",
    "\tprint(' > %.3f' % error)\n",
    "\treturn error\n",
    "\n",
    "# repeat evaluation of a config\n",
    "def repeat_evaluate(data, config, n_test, n_repeats=30):\n",
    "\t# fit and evaluate the model n times\n",
    "\tscores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)]\n",
    "\treturn scores\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_scores(name, scores):\n",
    "\t# print a summary\n",
    "\tscores_m, score_std = mean(scores), std(scores)\n",
    "\tprint('%s: %.3f RMSE (+/- %.3f)' % (name, scores_m, score_std))\n",
    "\t# box and whisker plot\n",
    "\tpyplot.boxplot(scores)\n",
    "\tpyplot.show()\n",
    "\n",
    "series = read_csv('monthly-car-sales.csv', header=0, index_col=0)\n",
    "data = series.values\n",
    "# data split\n",
    "n_test = 12\n",
    "# define config\n",
    "config = [3, 12, 256, 3, 200, 200, 100]\n",
    "# grid search\n",
    "scores = repeat_evaluate(data, config, n_test)\n",
    "# summarize scores\n",
    "summarize_scores('convlstm', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example prints the RMSE for each repeated evaluation of the model. The final averaged RMSE is reported at the end of about 1,660, which is lower than the naive model, but still higher than a SARIMA model. It is a result that is perhaps on par with the CNN-LSTM model. The standard deviation of this score is also very large, suggesting that the chosen configuration may not be as stable as the standalone CNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.8 Further Reading\n",
    "This section provides more resources on the topic if you are looking to go deeper.\n",
    "- pandas.DataFrame.shift API. http://pandas-docs.github.io/pandas-docs-travis/generated/pandas.DataFrame.shift.html\n",
    "- matplotlib.pyplot.boxplot API. https://matplotlib.org/api/_as_gen/matplotlib.pyplot.boxplot.html\n",
    "- Keras Sequential Model API. https://keras.io/models/sequential/\n",
    "- Keras Core Layers API. https://keras.io/layers/core/\n",
    "- Keras Convolutional Layers API. https://keras.io/layers/convolutional/\n",
    "- Keras Pooling Layers API. https://keras.io/layers/pooling/\n",
    "- Keras Recurrent Layers API. https://keras.io/layers/recurrent/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.9 Summary\n",
    "In this tutorial, you discovered how to develop a suite of deep learning models for univariate time series forecasting. Specifically, you learned:\n",
    "- How to develop a robust test harness using walk-forward validation for evaluating the performance of neural network models.\n",
    "- How to develop and evaluate simple Multilayer Perceptron and convolutional neural networks for time series forecasting.\n",
    "- How to develop and evaluate LSTMs, CNN-LSTMs, and ConvLSTM neural network models for time series forecasting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
